# UNICEF Guidance on AI and Children (Version 3)

**Updated guidance for governments and businesses to create AI policies and systems that uphold children's rights**

[Full Report](https://www.unicef.org/innocenti/media/11991/file/UNICEF-Innocenti-Guidance-on-AI-and-Children-3-2025.pdf)

---

## 10 Requirements for Child-Centred AI

### 1. Ensure Regulatory Frameworks, Oversight and Compliance for Child-Centred AI

- Review, update and, where necessary, develop comprehensive AI-related regulatory frameworks to integrate child rights
- Establish – or assign responsibility to existing – oversight or regulatory bodies to ensure compliance with AI principles and laws and set up support mechanisms for redress
- Ensure that government AI systems comply with AI-related laws and child rights law

---

### 2. Ensure Safety for Children

- Mandate child rights impact assessments of AI systems in AI strategies, policies, laws and regulations
- Continuously assess and monitor AI's impact on children throughout the entire AI development life cycle, and disclose results
- Require testing of AI systems for safety, security and robustness
- Eliminate harms and mitigate risks to children of harmful and illegal content that is generated, disseminated and/or amplified by AI, including mis/disinformation, cyberbullying and scams
- Prevent AI-enabled crimes against children such as child sexual abuse and exploitation
- Address risks from AI-enabled chatbots or companions
- Protect children from the harmful use of AI in armed conflict and cyber operations
- Leverage the use of AI systems, where appropriate, to promote children's safety and support those protecting children

---

### 3. Protect Children's Data and Privacy

- Responsibly handle data about and for children
- Adopt a privacy-by-design approach
- Protect groups
- Promote children's data agency

---

### 4. Ensure Non-Discrimination and Fairness for Children

- Actively support children in disadvantaged or vulnerable situations so that they may benefit from AI systems
- Reduce prejudicial bias against children, or certain groups of children, which leads to discrimination and exclusion

---

### 5. Provide Transparency, Explainability and Accountability for Children

- AI systems should clearly warn children and caregivers upfront that they are interacting with an AI, not a human
- Explicitly address children when promoting explainability and transparency of AI systems, and prevent anthropomorphizing such systems
- Use age-appropriate language to describe AI
- Design, develop and deploy AI systems so that they protect and support child users according to legal and policy frameworks, regardless of children's understandings of the system

---

### 6. Respect Human and Child Rights Through Responsible AI Practice

- Ensure respect for children's rights across all digital business activities involving AI
- Ensure a rights-based AI value chain for all inputs ranging from data to hardware and eliminate child labour and exploitation at all stages
- Ensure capacity-building on AI and child rights for top management and those in the AI life cycle, including designers, developers and researchers, and commit to action
- Capitalize on customers' demand for trusted and transparent AI solutions for children

---

### 7. Support Children's Best Interests, Development and Well-Being

- Prioritize how AI can benefit children, in particular in AI policies, laws and systems
- Develop and apply a child rights-by-design approach
- Integrate metrics and processes to support children's well-being in the use of AI
- Address negative environmental impacts from AI and digital infrastructure
- Leverage AI systems to support and increase environmental sustainability, including by ensuring a sustainable AI value chain

---

### 8. Ensure Inclusion of and for Children

- Support meaningful child participation, both in AI policies and governance, and in design, development and deployment processes
- Adopt an inclusive design approach when developing AI products that will be used by children or impact them
- Strive for diversity amongst those who design, develop, implement, research, regulate and oversee AI systems that children may use or be impacted by, including those collecting and processing AI data

---

### 9. Prepare and Skill Children for Present and Future Developments in AI

- Develop or update formal and informal education programmes for AI literacy and strengthen life skills and technical skills needed to flourish in an AI world, including in the future workplace
- Train, equip and support teachers on AI to put them at the centre, not replace them
- Provide guidance to teachers, schools and education departments to effectively procure and deploy AI and mitigate the risks
- Leverage the use of AI systems in education, when it is appropriate and based on evidence
- Develop and promote AI-related awareness campaigns for parents, caregivers and society as a whole
- Manage the impact of AI on the future of work to uphold children's rights

---

### 10. Create an Enabling Environment for Child-Centred AI

- Support infrastructure development to address the digital divide and aim for equitable sharing of the benefits of AI
- Invest, mobilize resources and create incentives for child-centred AI policies and programmes
- Support research on AI for and with children across the system's life cycle
- Engage in digital cooperation in the public interest and for upholding children's rights
- Foster a multi-stakeholder approach both in government and in business practices
- Support efforts towards interoperable AI, data and digital governance that provide equal opportunities and protections for children everywhere

---

## Cross-Cutting Considerations

- **Adapt to the national or local context**
- **Employ foresight** to better anticipate and govern AI
- **Be future ready**

## Impetus
Artificial intelligence (AI) is now front and centre in almost every major app
or platform that children use. Recent data reveals rapid adoption: 67 per cent
of UK teens now use AI (a figure that has almost doubled in two years),1
39 per cent of American elementary students learn through AI applications2
per cent of American elementary students learn through AI applications2
and 37 per cent of children aged 9–11 in Argentina turn to ChatGPT for
information.3
 Uptake, however, is not even: UNICEF research (forthcoming)
with 12,000 children aged 12–17 and their parents/caregivers found
substantial AI usage but wide divides between countries, leading to the
exclusion of some children. The little research available on children and AI
shows the differences are about more than access – disparities exist in types
of usage, attitudes to AI, trust levels, understanding of privacy protections
and exposure to harm.

Collectively, these changes bring opportunities and risks to children, young
people and their families, teachers and communities. New benefits that
could be leveraged include the use of AI systems to better support learning
and increase accessibility for children with disabilities. Novel risks include
AI-generated disinformation and emotional dependency on companion
chatbots. Real harms are experienced through AI-generated explicit
‘deepfakes’ and AI-generated child sexual abuse material (CSAM), sometimes
based on the images of real children. Essential questions remain unanswered,
such as what disruption AI systems may cause in children’s education, skill
needs and future workplaces?
Since 2021, there has been a much-needed uptick in efforts to support and
protect children in an AI world. From a governance perspective, these include
child-related legal stipulations in the EU AI Act4
 and the Council of Europe
Framework Convention on AI and human rights, democracy and the rule of
law.5
 Recommendations appear in the Joint Statement on AI and the Rights
of the Child, adopted by the United Nations (UN) Committee on the Rights of
the Child in 2025 and co-led by the International Telecommunication Union
(ITU) and UNICEF,6
 the UN High-level Advisory Body on AI’s report7
 and
the UNESCO Recommendation on the Ethics of AI.8
 There are also efforts
to research and engage children on the topic, notably by UNICEF, the Alan Turing Institute, the Children’s Parliament and the Scottish AI Alliance,9
 as well
as by research groups like Digital Futures for Children with EU Kids Online.10
Yet, despite children being at the forefront of AI adoption, little is
known about the mid- to long-term impact of AI on them; for example,
developmental (cognitive and psychological) and learning impacts, as well
as impacts on the societies in which they live. In addition, children remain at
the margin of shaping AI systems. This is especially true for children from the
Global South, for whom location, digital divides and severely limited access
to policy forums and AI design processes are exclusionary factors. Even
in wealthy countries in the Global North, most children are not sufficiently
engaged in such activities. If AI systems are to benefit every child and
function in their best interests, children must be urgently and meaningfully
included in AI governance and development processes. Particular attention
must be paid to those from the Global South, in rural areas, and from
marginalized or vulnerable communities.
The notable policy, research and engagement efforts towards child-centred
AI listed above are the exception, not the norm. Children’s rights are still not
receiving sufficient attention in AI policy, law, governance and development.11
As noted, there is very limited understanding of how this unprecedented
technological shift is shaping different children’s worldviews, development
and futures at large. Further, the growing climate of AI competition and
fragmentation between countries creates headwinds for national, regional
and global cooperation, resourcing and interoperability – all key for ensuring
greater protections and opportunities for children.
The message is clear: in order to uphold children’s rights, AI governance
and systems need to optimize opportunities, mitigate risks and eliminate
harms for children. The need to address the evidence gap on how AI impacts
children and their environments, ideally through participatory research and
decision-making, and to centre children in AI policies and systems has never
been more urgent or important.
This guidance draws on the UN Convention on the Rights of the Child
(CRC)12 to lay out the foundations for child-centred AI: today and in the
future, AI policies and systems should protect children, provide equitably
for their needs and rights and support their participation in an AI world by
contributing to the development and use of AI.

Children should be empowered with access to, and opportunity to benefit
from, AI systems. Building on this foundation, the guidance presents
ten requirements for child-centred AI, complementing key work already
underway, but with a central focus on children.


